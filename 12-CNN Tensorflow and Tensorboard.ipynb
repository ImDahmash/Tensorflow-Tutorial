{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_layer(input, size_in, size_out, name=\"Conv_Scope\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([5, 5, size_in, size_out], stddev=0.1), name=\"W_Conv_Scope\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B_Conv_Scope\")\n",
    "        conv = tf.nn.conv2d(input, w, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "        act = tf.nn.relu(conv + b)\n",
    "        tf.summary.histogram(\"Weights\", w)\n",
    "        tf.summary.histogram(\"Biases\", b)\n",
    "        tf.summary.histogram(\"Activations\", act)\n",
    "        return tf.nn.max_pool(act, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_layer(input, size_in, size_out, name=\"FC_Scope\"):\n",
    "    with tf.name_scope(name):\n",
    "        w = tf.Variable(tf.truncated_normal([size_in, size_out], stddev=0.1), name=\"W_FC_Scope\")\n",
    "        b = tf.Variable(tf.constant(0.1, shape=[size_out]), name=\"B_FC_Scope\")\n",
    "        act = tf.matmul(input, w) + b\n",
    "        tf.summary.histogram(\"Weights\", w)\n",
    "        tf.summary.histogram(\"Biases\", b)\n",
    "        tf.summary.histogram(\"Activations\", act)\n",
    "        return act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "y_train = y_train.astype('int64')\n",
    "y_test = y_test.astype('int64')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 784], name=\"Input_X\")\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "tf.summary.image('Sample_Image', x_image, 5)\n",
    "\n",
    "y = tf.placeholder(tf.int64, shape=[None,], name=\"Output_Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1 = conv_layer(x_image, 1, 32, name=\"Conv_Layer_1\")\n",
    "conv_out = conv_layer(conv1, 32, 64, name=\"Conv_Layer_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened = tf.reshape(conv_out, [-1, 7 * 7 * 64], name=\"Flattened_Layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Fc1/Relu:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1 = fc_layer(flattened, 7 * 7 * 64, 1024, name=\"FC_Layer\")\n",
    "relu = tf.nn.relu(fc1, name=\"Relu_Final\")\n",
    "tf.summary.histogram(\"Fc1/Relu\", relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = fc_layer(relu, 1024, 10, name=\"Logits_Results\")\n",
    "softmax = tf.nn.softmax(logits, name=\"Logits_Softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy_Scope\"):\n",
    "    matches = tf.equal(tf.argmax(softmax, 1), y, name=\"Matches_\")\n",
    "    acc = tf.reduce_mean(tf.cast(matches, tf.float32), name=\"Accuracy_Train\")\n",
    "    tf.summary.scalar(\"Accuracy_Value\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Loss_Scope\"):\n",
    "    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y), name=\"Loss_Function\")\n",
    "    tf.summary.scalar(\"Loss_Value\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Train_OP_Scope\"):\n",
    "    train_op = tf.train.AdamOptimizer(0.001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergerd_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch No: 1 of 5\n",
      "Loss: 0.122876726 Accuracy: 0.972\n",
      "00 Seconds\n",
      "\n",
      "\n",
      "Epoch No: 2 of 5\n",
      "Loss: 0.06737193 Accuracy: 0.989\n",
      "59 Seconds\n",
      "\n",
      "\n",
      "Epoch No: 3 of 5\n",
      "Loss: 0.05339623 Accuracy: 0.992\n",
      "59 Seconds\n",
      "\n",
      "\n",
      "Epoch No: 4 of 5\n",
      "Loss: 0.048450682 Accuracy: 0.992\n",
      "59 Seconds\n",
      "\n",
      "\n",
      "Epoch No: 5 of 5\n",
      "Loss: 0.04075613 Accuracy: 0.993\n",
      "59 Seconds\n",
      "\n",
      "\n",
      "Finish Training :-)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    writer = tf.summary.FileWriter(\"./log/CNN_TB/Round1\")\n",
    "    writer.add_graph(sess.graph)\n",
    "\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    epochs = 5\n",
    "    batch_size = 1000\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for curr_batch in range(len(x_train) // batch_size):\n",
    "            from_i = curr_batch * batch_size\n",
    "            to_i = (curr_batch * batch_size) + batch_size\n",
    "            \n",
    "            loss_, _, acc_, summ = sess.run([loss, train_op, acc, mergerd_summary],\n",
    "                                      feed_dict={x: x_train[from_i : to_i].reshape(batch_size, 784), \n",
    "                                                 y: y_train[from_i : to_i]})\n",
    "            \n",
    "        writer.add_summary(summ, i)  \n",
    "        losses.append(loss_)\n",
    "        accuracies.append(acc_)\n",
    "        \n",
    "        print(\"Epoch No: \" + str(i + 1) + \" of \" + str(epochs))\n",
    "        print(\"Loss: \" + str(loss_) + \" Accuracy: \" + str(acc_))\n",
    "        \n",
    "        elapsed_time = time.time() - start_time\n",
    "        print(time.strftime(\"%S\", time.gmtime(elapsed_time)) + \" Seconds\")\n",
    "        \n",
    "        print(\"\\n\")\n",
    "        \n",
    "    saver.save(sess, \"./log/CNN_TF_Tensorboard.ckpt\")\n",
    "    print(\"Finish Training :-)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tensorboard --logdir log/CNN_TB --port=6007"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
